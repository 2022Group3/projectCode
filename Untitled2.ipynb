{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "10B3ms5D0QaeB9aZO0ankJb68NzM4wowQ",
      "authorship_tag": "ABX9TyPhEIieU3fO087yDXAipM0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022Group3/projectCode/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uwADnnxsUgw6"
      },
      "outputs": [],
      "source": [
        "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgnqS6FOUjOx",
        "outputId": "aeb39210-d27a-4840-eda5-10f7e8415bd0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  data=np.load(r'drive/MyDrive/dir/data_modified.npz')\n",
        "  data=dict(zip((\"{}\".format(k) for k in data),(data[k] for k in data)))\n",
        "  trainX=data['train']\n",
        "  trainy=data['ytrain']\n",
        "  validationX=data['validation']\n",
        "  validationy=data['yvalidation']\n",
        "  testX=data['test']\n",
        "  testy=data['ytest']\n",
        "  return trainX,trainy,validationX,validationy,testX,testy"
      ],
      "metadata": {
        "id": "9sF4AM2Qh9tQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train,validation):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  validation_norm = validation.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  validation_norm = validation / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm, validation_norm"
      ],
      "metadata": {
        "id": "nDnipp1Qj_Tq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2,2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(16, activation='softmax'))\n",
        "\t# compile model\n",
        "  opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "  # model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  # model.compile(optimizer=opt,loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "1IYVqusZpFhy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='validation')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "uV2oqzSxxHFt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainy,validationX,validationy, testX, testy = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, validationX = prep_pixels(trainX, validationX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainy, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=250, validation_data=(validationX, validationy), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(validationX, validationy, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "  return model"
      ],
      "metadata": {
        "id": "0mGnuKi-xJ-9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALhHiHlsxNbw",
        "outputId": "83920e7f-238a-4766-e2a4-dcf0e58a7940"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 2.6701 - accuracy: 0.2303 - val_loss: 1.8413 - val_accuracy: 0.3943\n",
            "Epoch 2/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 2.0417 - accuracy: 0.3342 - val_loss: 1.7716 - val_accuracy: 0.3979\n",
            "Epoch 3/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.8769 - accuracy: 0.3805 - val_loss: 1.7168 - val_accuracy: 0.4283\n",
            "Epoch 4/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.7862 - accuracy: 0.4096 - val_loss: 1.6485 - val_accuracy: 0.4456\n",
            "Epoch 5/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.7282 - accuracy: 0.4254 - val_loss: 1.7840 - val_accuracy: 0.4103\n",
            "Epoch 6/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.6693 - accuracy: 0.4467 - val_loss: 1.5370 - val_accuracy: 0.4881\n",
            "Epoch 7/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.6225 - accuracy: 0.4638 - val_loss: 1.6206 - val_accuracy: 0.4605\n",
            "Epoch 8/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.5706 - accuracy: 0.4806 - val_loss: 1.5951 - val_accuracy: 0.4772\n",
            "Epoch 9/250\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 1.5380 - accuracy: 0.4952 - val_loss: 1.5051 - val_accuracy: 0.4983\n",
            "Epoch 10/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.5002 - accuracy: 0.5077 - val_loss: 1.5477 - val_accuracy: 0.4937\n",
            "Epoch 11/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.4660 - accuracy: 0.5168 - val_loss: 1.4296 - val_accuracy: 0.5268\n",
            "Epoch 12/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.4378 - accuracy: 0.5251 - val_loss: 1.3438 - val_accuracy: 0.5549\n",
            "Epoch 13/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.4064 - accuracy: 0.5359 - val_loss: 1.3701 - val_accuracy: 0.5492\n",
            "Epoch 14/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.3743 - accuracy: 0.5459 - val_loss: 1.2994 - val_accuracy: 0.5705\n",
            "Epoch 15/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.3569 - accuracy: 0.5510 - val_loss: 1.4358 - val_accuracy: 0.5276\n",
            "Epoch 16/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.3381 - accuracy: 0.5591 - val_loss: 1.2764 - val_accuracy: 0.5723\n",
            "Epoch 17/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.3140 - accuracy: 0.5689 - val_loss: 1.2507 - val_accuracy: 0.5857\n",
            "Epoch 18/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.2976 - accuracy: 0.5740 - val_loss: 1.2178 - val_accuracy: 0.5937\n",
            "Epoch 19/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.2753 - accuracy: 0.5813 - val_loss: 1.1781 - val_accuracy: 0.6107\n",
            "Epoch 20/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 1.2567 - accuracy: 0.5870 - val_loss: 1.2011 - val_accuracy: 0.6016\n",
            "Epoch 21/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.2377 - accuracy: 0.5944 - val_loss: 1.2514 - val_accuracy: 0.5868\n",
            "Epoch 22/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2223 - accuracy: 0.5998 - val_loss: 1.0958 - val_accuracy: 0.6355\n",
            "Epoch 23/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.2086 - accuracy: 0.6034 - val_loss: 1.1592 - val_accuracy: 0.6135\n",
            "Epoch 24/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.1927 - accuracy: 0.6074 - val_loss: 1.1174 - val_accuracy: 0.6205\n",
            "Epoch 25/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.1826 - accuracy: 0.6128 - val_loss: 1.0871 - val_accuracy: 0.6376\n",
            "Epoch 26/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.1685 - accuracy: 0.6137 - val_loss: 1.1030 - val_accuracy: 0.6327\n",
            "Epoch 27/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1546 - accuracy: 0.6203 - val_loss: 1.1259 - val_accuracy: 0.6260\n",
            "Epoch 28/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1460 - accuracy: 0.6239 - val_loss: 1.0971 - val_accuracy: 0.6331\n",
            "Epoch 29/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.1303 - accuracy: 0.6262 - val_loss: 1.0115 - val_accuracy: 0.6628\n",
            "Epoch 30/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.1212 - accuracy: 0.6297 - val_loss: 1.0293 - val_accuracy: 0.6527\n",
            "Epoch 31/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.1158 - accuracy: 0.6334 - val_loss: 1.0315 - val_accuracy: 0.6531\n",
            "Epoch 32/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 1.1004 - accuracy: 0.6400 - val_loss: 1.0294 - val_accuracy: 0.6588\n",
            "Epoch 33/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.0863 - accuracy: 0.6431 - val_loss: 1.0526 - val_accuracy: 0.6471\n",
            "Epoch 34/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.0834 - accuracy: 0.6444 - val_loss: 1.0639 - val_accuracy: 0.6449\n",
            "Epoch 35/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0764 - accuracy: 0.6460 - val_loss: 0.9804 - val_accuracy: 0.6743\n",
            "Epoch 36/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.0653 - accuracy: 0.6503 - val_loss: 1.0628 - val_accuracy: 0.6420\n",
            "Epoch 37/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0567 - accuracy: 0.6542 - val_loss: 1.1098 - val_accuracy: 0.6377\n",
            "Epoch 38/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0501 - accuracy: 0.6554 - val_loss: 0.9591 - val_accuracy: 0.6800\n",
            "Epoch 39/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0440 - accuracy: 0.6560 - val_loss: 0.9832 - val_accuracy: 0.6743\n",
            "Epoch 40/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 1.0334 - accuracy: 0.6614 - val_loss: 0.8949 - val_accuracy: 0.7019\n",
            "Epoch 41/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0284 - accuracy: 0.6625 - val_loss: 0.9774 - val_accuracy: 0.6752\n",
            "Epoch 42/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0200 - accuracy: 0.6646 - val_loss: 0.9062 - val_accuracy: 0.7004\n",
            "Epoch 43/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 1.0149 - accuracy: 0.6680 - val_loss: 0.9298 - val_accuracy: 0.6883\n",
            "Epoch 44/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9985 - accuracy: 0.6700 - val_loss: 1.0124 - val_accuracy: 0.6660\n",
            "Epoch 45/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9938 - accuracy: 0.6746 - val_loss: 0.8468 - val_accuracy: 0.7140\n",
            "Epoch 46/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9915 - accuracy: 0.6743 - val_loss: 0.9158 - val_accuracy: 0.6929\n",
            "Epoch 47/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9803 - accuracy: 0.6787 - val_loss: 1.0048 - val_accuracy: 0.6680\n",
            "Epoch 48/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9671 - accuracy: 0.6820 - val_loss: 0.8718 - val_accuracy: 0.7097\n",
            "Epoch 49/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.9650 - accuracy: 0.6822 - val_loss: 0.9275 - val_accuracy: 0.6905\n",
            "Epoch 50/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9581 - accuracy: 0.6831 - val_loss: 0.8762 - val_accuracy: 0.7067\n",
            "Epoch 51/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9529 - accuracy: 0.6868 - val_loss: 0.8498 - val_accuracy: 0.7179\n",
            "Epoch 52/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9481 - accuracy: 0.6874 - val_loss: 0.8808 - val_accuracy: 0.7092\n",
            "Epoch 53/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9454 - accuracy: 0.6888 - val_loss: 0.8363 - val_accuracy: 0.7197\n",
            "Epoch 54/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9313 - accuracy: 0.6968 - val_loss: 0.8055 - val_accuracy: 0.7331\n",
            "Epoch 55/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9340 - accuracy: 0.6910 - val_loss: 0.8148 - val_accuracy: 0.7275\n",
            "Epoch 56/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9252 - accuracy: 0.6962 - val_loss: 0.8712 - val_accuracy: 0.7111\n",
            "Epoch 57/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9184 - accuracy: 0.6998 - val_loss: 0.9327 - val_accuracy: 0.6927\n",
            "Epoch 58/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9150 - accuracy: 0.6998 - val_loss: 0.8183 - val_accuracy: 0.7225\n",
            "Epoch 59/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9137 - accuracy: 0.6992 - val_loss: 0.7860 - val_accuracy: 0.7355\n",
            "Epoch 60/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.9069 - accuracy: 0.7048 - val_loss: 0.8488 - val_accuracy: 0.7177\n",
            "Epoch 61/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8948 - accuracy: 0.7066 - val_loss: 0.7915 - val_accuracy: 0.7365\n",
            "Epoch 62/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8946 - accuracy: 0.7053 - val_loss: 0.7958 - val_accuracy: 0.7391\n",
            "Epoch 63/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.8913 - accuracy: 0.7089 - val_loss: 0.8787 - val_accuracy: 0.7112\n",
            "Epoch 64/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8832 - accuracy: 0.7100 - val_loss: 0.7721 - val_accuracy: 0.7439\n",
            "Epoch 65/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.8764 - accuracy: 0.7129 - val_loss: 0.7764 - val_accuracy: 0.7420\n",
            "Epoch 66/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8746 - accuracy: 0.7129 - val_loss: 0.8388 - val_accuracy: 0.7195\n",
            "Epoch 67/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8649 - accuracy: 0.7147 - val_loss: 0.8586 - val_accuracy: 0.7113\n",
            "Epoch 68/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8656 - accuracy: 0.7152 - val_loss: 0.7891 - val_accuracy: 0.7383\n",
            "Epoch 69/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8626 - accuracy: 0.7171 - val_loss: 0.7578 - val_accuracy: 0.7449\n",
            "Epoch 70/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.8584 - accuracy: 0.7167 - val_loss: 0.7874 - val_accuracy: 0.7377\n",
            "Epoch 71/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8525 - accuracy: 0.7214 - val_loss: 0.7464 - val_accuracy: 0.7564\n",
            "Epoch 72/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8502 - accuracy: 0.7232 - val_loss: 0.7351 - val_accuracy: 0.7555\n",
            "Epoch 73/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8418 - accuracy: 0.7243 - val_loss: 0.7359 - val_accuracy: 0.7540\n",
            "Epoch 74/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8344 - accuracy: 0.7256 - val_loss: 0.7489 - val_accuracy: 0.7520\n",
            "Epoch 75/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8336 - accuracy: 0.7264 - val_loss: 0.7048 - val_accuracy: 0.7631\n",
            "Epoch 76/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8385 - accuracy: 0.7237 - val_loss: 0.7686 - val_accuracy: 0.7513\n",
            "Epoch 77/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.8303 - accuracy: 0.7293 - val_loss: 0.7582 - val_accuracy: 0.7509\n",
            "Epoch 78/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8248 - accuracy: 0.7318 - val_loss: 0.7501 - val_accuracy: 0.7517\n",
            "Epoch 79/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8133 - accuracy: 0.7335 - val_loss: 0.7421 - val_accuracy: 0.7577\n",
            "Epoch 80/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8187 - accuracy: 0.7316 - val_loss: 0.6955 - val_accuracy: 0.7721\n",
            "Epoch 81/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8076 - accuracy: 0.7341 - val_loss: 0.7396 - val_accuracy: 0.7541\n",
            "Epoch 82/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8112 - accuracy: 0.7361 - val_loss: 0.8705 - val_accuracy: 0.7223\n",
            "Epoch 83/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.8079 - accuracy: 0.7342 - val_loss: 0.7580 - val_accuracy: 0.7511\n",
            "Epoch 84/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8068 - accuracy: 0.7385 - val_loss: 0.7025 - val_accuracy: 0.7696\n",
            "Epoch 85/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7998 - accuracy: 0.7366 - val_loss: 0.6885 - val_accuracy: 0.7713\n",
            "Epoch 86/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7949 - accuracy: 0.7387 - val_loss: 0.6917 - val_accuracy: 0.7712\n",
            "Epoch 87/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7980 - accuracy: 0.7386 - val_loss: 0.6782 - val_accuracy: 0.7707\n",
            "Epoch 88/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7819 - accuracy: 0.7449 - val_loss: 0.7298 - val_accuracy: 0.7604\n",
            "Epoch 89/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7880 - accuracy: 0.7424 - val_loss: 0.7139 - val_accuracy: 0.7617\n",
            "Epoch 90/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7821 - accuracy: 0.7433 - val_loss: 0.6780 - val_accuracy: 0.7739\n",
            "Epoch 91/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7805 - accuracy: 0.7449 - val_loss: 0.6868 - val_accuracy: 0.7771\n",
            "Epoch 92/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7762 - accuracy: 0.7456 - val_loss: 0.6957 - val_accuracy: 0.7723\n",
            "Epoch 93/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7713 - accuracy: 0.7471 - val_loss: 0.6934 - val_accuracy: 0.7729\n",
            "Epoch 94/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7689 - accuracy: 0.7479 - val_loss: 0.6821 - val_accuracy: 0.7772\n",
            "Epoch 95/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7633 - accuracy: 0.7486 - val_loss: 0.7117 - val_accuracy: 0.7669\n",
            "Epoch 96/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.7634 - accuracy: 0.7491 - val_loss: 0.6436 - val_accuracy: 0.7863\n",
            "Epoch 97/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7598 - accuracy: 0.7513 - val_loss: 0.6570 - val_accuracy: 0.7809\n",
            "Epoch 98/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7572 - accuracy: 0.7519 - val_loss: 0.7206 - val_accuracy: 0.7651\n",
            "Epoch 99/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7582 - accuracy: 0.7528 - val_loss: 0.6839 - val_accuracy: 0.7759\n",
            "Epoch 100/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7523 - accuracy: 0.7532 - val_loss: 0.6535 - val_accuracy: 0.7871\n",
            "Epoch 101/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.7506 - accuracy: 0.7521 - val_loss: 0.6587 - val_accuracy: 0.7812\n",
            "Epoch 102/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7516 - accuracy: 0.7552 - val_loss: 0.6885 - val_accuracy: 0.7760\n",
            "Epoch 103/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.7505 - accuracy: 0.7553 - val_loss: 0.6523 - val_accuracy: 0.7867\n",
            "Epoch 104/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7430 - accuracy: 0.7588 - val_loss: 0.6825 - val_accuracy: 0.7772\n",
            "Epoch 105/250\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7426 - accuracy: 0.7573 - val_loss: 0.6821 - val_accuracy: 0.7767\n",
            "Epoch 106/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7330 - accuracy: 0.7603 - val_loss: 0.6627 - val_accuracy: 0.7836\n",
            "Epoch 107/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7323 - accuracy: 0.7598 - val_loss: 0.6895 - val_accuracy: 0.7793\n",
            "Epoch 108/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7295 - accuracy: 0.7615 - val_loss: 0.6382 - val_accuracy: 0.7940\n",
            "Epoch 109/250\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.7288 - accuracy: 0.7615 - val_loss: 0.6773 - val_accuracy: 0.7773\n",
            "Epoch 110/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7315 - accuracy: 0.7615 - val_loss: 0.6468 - val_accuracy: 0.7857\n",
            "Epoch 111/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7257 - accuracy: 0.7625 - val_loss: 0.6133 - val_accuracy: 0.7957\n",
            "Epoch 112/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7172 - accuracy: 0.7662 - val_loss: 0.7094 - val_accuracy: 0.7651\n",
            "Epoch 113/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7185 - accuracy: 0.7660 - val_loss: 0.6327 - val_accuracy: 0.7956\n",
            "Epoch 114/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.7221 - accuracy: 0.7644 - val_loss: 0.6720 - val_accuracy: 0.7819\n",
            "Epoch 115/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7145 - accuracy: 0.7664 - val_loss: 0.6552 - val_accuracy: 0.7839\n",
            "Epoch 116/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7066 - accuracy: 0.7694 - val_loss: 0.6227 - val_accuracy: 0.7973\n",
            "Epoch 117/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7085 - accuracy: 0.7687 - val_loss: 0.6509 - val_accuracy: 0.7856\n",
            "Epoch 118/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7071 - accuracy: 0.7694 - val_loss: 0.6157 - val_accuracy: 0.7959\n",
            "Epoch 119/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7020 - accuracy: 0.7713 - val_loss: 0.6186 - val_accuracy: 0.7984\n",
            "Epoch 120/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7085 - accuracy: 0.7695 - val_loss: 0.6331 - val_accuracy: 0.7931\n",
            "Epoch 121/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6956 - accuracy: 0.7724 - val_loss: 0.6293 - val_accuracy: 0.7920\n",
            "Epoch 122/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7008 - accuracy: 0.7710 - val_loss: 0.6748 - val_accuracy: 0.7807\n",
            "Epoch 123/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6955 - accuracy: 0.7727 - val_loss: 0.6199 - val_accuracy: 0.7961\n",
            "Epoch 124/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6989 - accuracy: 0.7692 - val_loss: 0.6363 - val_accuracy: 0.7945\n",
            "Epoch 125/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6909 - accuracy: 0.7735 - val_loss: 0.6594 - val_accuracy: 0.7828\n",
            "Epoch 126/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6815 - accuracy: 0.7764 - val_loss: 0.7131 - val_accuracy: 0.7707\n",
            "Epoch 127/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6869 - accuracy: 0.7737 - val_loss: 0.6198 - val_accuracy: 0.7976\n",
            "Epoch 128/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6883 - accuracy: 0.7746 - val_loss: 0.5760 - val_accuracy: 0.8152\n",
            "Epoch 129/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.6855 - accuracy: 0.7772 - val_loss: 0.6347 - val_accuracy: 0.7947\n",
            "Epoch 130/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6809 - accuracy: 0.7771 - val_loss: 0.6186 - val_accuracy: 0.7967\n",
            "Epoch 131/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6801 - accuracy: 0.7781 - val_loss: 0.5994 - val_accuracy: 0.8024\n",
            "Epoch 132/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6736 - accuracy: 0.7789 - val_loss: 0.6184 - val_accuracy: 0.8016\n",
            "Epoch 133/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6862 - accuracy: 0.7765 - val_loss: 0.6442 - val_accuracy: 0.7916\n",
            "Epoch 134/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6698 - accuracy: 0.7834 - val_loss: 0.6183 - val_accuracy: 0.8007\n",
            "Epoch 135/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6679 - accuracy: 0.7822 - val_loss: 0.6026 - val_accuracy: 0.8028\n",
            "Epoch 136/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6704 - accuracy: 0.7820 - val_loss: 0.5936 - val_accuracy: 0.8076\n",
            "Epoch 137/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6605 - accuracy: 0.7841 - val_loss: 0.6268 - val_accuracy: 0.7980\n",
            "Epoch 138/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6691 - accuracy: 0.7820 - val_loss: 0.6257 - val_accuracy: 0.7985\n",
            "Epoch 139/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6674 - accuracy: 0.7842 - val_loss: 0.6163 - val_accuracy: 0.8001\n",
            "Epoch 140/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6563 - accuracy: 0.7871 - val_loss: 0.6344 - val_accuracy: 0.7939\n",
            "Epoch 141/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6615 - accuracy: 0.7841 - val_loss: 0.6254 - val_accuracy: 0.7973\n",
            "Epoch 142/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6623 - accuracy: 0.7836 - val_loss: 0.5834 - val_accuracy: 0.8083\n",
            "Epoch 143/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6570 - accuracy: 0.7838 - val_loss: 0.6269 - val_accuracy: 0.7932\n",
            "Epoch 144/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6532 - accuracy: 0.7862 - val_loss: 0.6068 - val_accuracy: 0.8057\n",
            "Epoch 145/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6583 - accuracy: 0.7857 - val_loss: 0.5970 - val_accuracy: 0.8057\n",
            "Epoch 146/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6512 - accuracy: 0.7879 - val_loss: 0.6153 - val_accuracy: 0.8028\n",
            "Epoch 147/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6458 - accuracy: 0.7870 - val_loss: 0.6082 - val_accuracy: 0.8043\n",
            "Epoch 148/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6483 - accuracy: 0.7871 - val_loss: 0.6227 - val_accuracy: 0.7997\n",
            "Epoch 149/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6492 - accuracy: 0.7883 - val_loss: 0.5653 - val_accuracy: 0.8147\n",
            "Epoch 150/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6459 - accuracy: 0.7876 - val_loss: 0.5795 - val_accuracy: 0.8119\n",
            "Epoch 151/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6425 - accuracy: 0.7900 - val_loss: 0.5895 - val_accuracy: 0.8101\n",
            "Epoch 152/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6392 - accuracy: 0.7898 - val_loss: 0.5815 - val_accuracy: 0.8144\n",
            "Epoch 153/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6307 - accuracy: 0.7923 - val_loss: 0.6030 - val_accuracy: 0.8051\n",
            "Epoch 154/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6305 - accuracy: 0.7921 - val_loss: 0.5734 - val_accuracy: 0.8129\n",
            "Epoch 155/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6322 - accuracy: 0.7942 - val_loss: 0.5743 - val_accuracy: 0.8151\n",
            "Epoch 156/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6339 - accuracy: 0.7939 - val_loss: 0.5985 - val_accuracy: 0.8016\n",
            "Epoch 157/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6361 - accuracy: 0.7920 - val_loss: 0.6356 - val_accuracy: 0.7961\n",
            "Epoch 158/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6337 - accuracy: 0.7945 - val_loss: 0.5915 - val_accuracy: 0.8112\n",
            "Epoch 159/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6237 - accuracy: 0.7952 - val_loss: 0.6403 - val_accuracy: 0.7940\n",
            "Epoch 160/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6238 - accuracy: 0.7980 - val_loss: 0.6586 - val_accuracy: 0.7897\n",
            "Epoch 161/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6269 - accuracy: 0.7941 - val_loss: 0.5816 - val_accuracy: 0.8135\n",
            "Epoch 162/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6246 - accuracy: 0.7949 - val_loss: 0.6104 - val_accuracy: 0.8077\n",
            "Epoch 163/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6326 - accuracy: 0.7932 - val_loss: 0.5744 - val_accuracy: 0.8148\n",
            "Epoch 164/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6303 - accuracy: 0.7943 - val_loss: 0.5885 - val_accuracy: 0.8131\n",
            "Epoch 165/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6134 - accuracy: 0.7991 - val_loss: 0.5828 - val_accuracy: 0.8113\n",
            "Epoch 166/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6132 - accuracy: 0.7978 - val_loss: 0.5687 - val_accuracy: 0.8199\n",
            "Epoch 167/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6156 - accuracy: 0.7990 - val_loss: 0.5988 - val_accuracy: 0.8064\n",
            "Epoch 168/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6180 - accuracy: 0.7967 - val_loss: 0.5732 - val_accuracy: 0.8127\n",
            "Epoch 169/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6161 - accuracy: 0.7993 - val_loss: 0.6002 - val_accuracy: 0.8092\n",
            "Epoch 170/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6079 - accuracy: 0.8018 - val_loss: 0.5789 - val_accuracy: 0.8161\n",
            "Epoch 171/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6102 - accuracy: 0.8010 - val_loss: 0.5699 - val_accuracy: 0.8173\n",
            "Epoch 172/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6066 - accuracy: 0.8019 - val_loss: 0.5642 - val_accuracy: 0.8165\n",
            "Epoch 173/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6035 - accuracy: 0.8025 - val_loss: 0.5920 - val_accuracy: 0.8105\n",
            "Epoch 174/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6053 - accuracy: 0.8008 - val_loss: 0.5506 - val_accuracy: 0.8263\n",
            "Epoch 175/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6050 - accuracy: 0.8013 - val_loss: 0.5762 - val_accuracy: 0.8160\n",
            "Epoch 176/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6066 - accuracy: 0.8033 - val_loss: 0.6285 - val_accuracy: 0.8004\n",
            "Epoch 177/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5971 - accuracy: 0.8045 - val_loss: 0.5700 - val_accuracy: 0.8173\n",
            "Epoch 178/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6018 - accuracy: 0.8020 - val_loss: 0.5630 - val_accuracy: 0.8177\n",
            "Epoch 179/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6047 - accuracy: 0.8010 - val_loss: 0.5599 - val_accuracy: 0.8203\n",
            "Epoch 180/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5990 - accuracy: 0.8042 - val_loss: 0.5752 - val_accuracy: 0.8155\n",
            "Epoch 181/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5935 - accuracy: 0.8045 - val_loss: 0.6038 - val_accuracy: 0.8077\n",
            "Epoch 182/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5913 - accuracy: 0.8075 - val_loss: 0.5564 - val_accuracy: 0.8249\n",
            "Epoch 183/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5934 - accuracy: 0.8071 - val_loss: 0.5620 - val_accuracy: 0.8187\n",
            "Epoch 184/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5951 - accuracy: 0.8059 - val_loss: 0.5704 - val_accuracy: 0.8157\n",
            "Epoch 185/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5907 - accuracy: 0.8094 - val_loss: 0.5279 - val_accuracy: 0.8316\n",
            "Epoch 186/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5869 - accuracy: 0.8080 - val_loss: 0.5654 - val_accuracy: 0.8225\n",
            "Epoch 187/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5855 - accuracy: 0.8089 - val_loss: 0.5588 - val_accuracy: 0.8213\n",
            "Epoch 188/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5917 - accuracy: 0.8054 - val_loss: 0.5470 - val_accuracy: 0.8224\n",
            "Epoch 189/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5826 - accuracy: 0.8088 - val_loss: 0.5577 - val_accuracy: 0.8181\n",
            "Epoch 190/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5891 - accuracy: 0.8085 - val_loss: 0.7160 - val_accuracy: 0.7813\n",
            "Epoch 191/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5797 - accuracy: 0.8084 - val_loss: 0.5857 - val_accuracy: 0.8144\n",
            "Epoch 192/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5902 - accuracy: 0.8069 - val_loss: 0.5678 - val_accuracy: 0.8188\n",
            "Epoch 193/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5820 - accuracy: 0.8088 - val_loss: 0.5470 - val_accuracy: 0.8240\n",
            "Epoch 194/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5806 - accuracy: 0.8097 - val_loss: 0.5888 - val_accuracy: 0.8135\n",
            "Epoch 195/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5803 - accuracy: 0.8108 - val_loss: 0.5495 - val_accuracy: 0.8263\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5835 - accuracy: 0.8108 - val_loss: 0.6014 - val_accuracy: 0.8088\n",
            "Epoch 197/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5755 - accuracy: 0.8126 - val_loss: 0.5752 - val_accuracy: 0.8191\n",
            "Epoch 198/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5753 - accuracy: 0.8104 - val_loss: 0.5499 - val_accuracy: 0.8260\n",
            "Epoch 199/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5693 - accuracy: 0.8150 - val_loss: 0.5740 - val_accuracy: 0.8153\n",
            "Epoch 200/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5684 - accuracy: 0.8126 - val_loss: 0.5834 - val_accuracy: 0.8153\n",
            "Epoch 201/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5743 - accuracy: 0.8135 - val_loss: 0.5672 - val_accuracy: 0.8185\n",
            "Epoch 202/250\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.5747 - accuracy: 0.8099 - val_loss: 0.5577 - val_accuracy: 0.8239\n",
            "Epoch 203/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5687 - accuracy: 0.8155 - val_loss: 0.5492 - val_accuracy: 0.8229\n",
            "Epoch 204/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5640 - accuracy: 0.8156 - val_loss: 0.5688 - val_accuracy: 0.8180\n",
            "Epoch 205/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5672 - accuracy: 0.8149 - val_loss: 0.5317 - val_accuracy: 0.8307\n",
            "Epoch 206/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5629 - accuracy: 0.8140 - val_loss: 0.5479 - val_accuracy: 0.8235\n",
            "Epoch 207/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5707 - accuracy: 0.8132 - val_loss: 0.5578 - val_accuracy: 0.8191\n",
            "Epoch 208/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5624 - accuracy: 0.8154 - val_loss: 0.5428 - val_accuracy: 0.8253\n",
            "Epoch 209/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5662 - accuracy: 0.8153 - val_loss: 0.5612 - val_accuracy: 0.8197\n",
            "Epoch 210/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5626 - accuracy: 0.8165 - val_loss: 0.5452 - val_accuracy: 0.8267\n",
            "Epoch 211/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5631 - accuracy: 0.8157 - val_loss: 0.5353 - val_accuracy: 0.8297\n",
            "Epoch 212/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5632 - accuracy: 0.8165 - val_loss: 0.5410 - val_accuracy: 0.8284\n",
            "Epoch 213/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5566 - accuracy: 0.8177 - val_loss: 0.5771 - val_accuracy: 0.8160\n",
            "Epoch 214/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5621 - accuracy: 0.8150 - val_loss: 0.5525 - val_accuracy: 0.8219\n",
            "Epoch 215/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5527 - accuracy: 0.8194 - val_loss: 0.5228 - val_accuracy: 0.8319\n",
            "Epoch 216/250\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5598 - accuracy: 0.8164 - val_loss: 0.5317 - val_accuracy: 0.8315\n",
            "Epoch 217/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5521 - accuracy: 0.8183 - val_loss: 0.5584 - val_accuracy: 0.8199\n",
            "Epoch 218/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5551 - accuracy: 0.8167 - val_loss: 0.5080 - val_accuracy: 0.8363\n",
            "Epoch 219/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5505 - accuracy: 0.8167 - val_loss: 0.5547 - val_accuracy: 0.8253\n",
            "Epoch 220/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5541 - accuracy: 0.8178 - val_loss: 0.5444 - val_accuracy: 0.8248\n",
            "Epoch 221/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5469 - accuracy: 0.8220 - val_loss: 0.5507 - val_accuracy: 0.8243\n",
            "Epoch 222/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5502 - accuracy: 0.8195 - val_loss: 0.5324 - val_accuracy: 0.8319\n",
            "Epoch 223/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5475 - accuracy: 0.8212 - val_loss: 0.5523 - val_accuracy: 0.8237\n",
            "Epoch 224/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5467 - accuracy: 0.8201 - val_loss: 0.5303 - val_accuracy: 0.8309\n",
            "Epoch 225/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5458 - accuracy: 0.8231 - val_loss: 0.5307 - val_accuracy: 0.8299\n",
            "Epoch 226/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5478 - accuracy: 0.8204 - val_loss: 0.5353 - val_accuracy: 0.8293\n",
            "Epoch 227/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5467 - accuracy: 0.8224 - val_loss: 0.5484 - val_accuracy: 0.8268\n",
            "Epoch 228/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5437 - accuracy: 0.8203 - val_loss: 0.5210 - val_accuracy: 0.8340\n",
            "Epoch 229/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5398 - accuracy: 0.8228 - val_loss: 0.5079 - val_accuracy: 0.8401\n",
            "Epoch 230/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5381 - accuracy: 0.8229 - val_loss: 0.5204 - val_accuracy: 0.8367\n",
            "Epoch 231/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5448 - accuracy: 0.8219 - val_loss: 0.5538 - val_accuracy: 0.8240\n",
            "Epoch 232/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5413 - accuracy: 0.8220 - val_loss: 0.5276 - val_accuracy: 0.8299\n",
            "Epoch 233/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5437 - accuracy: 0.8215 - val_loss: 0.5174 - val_accuracy: 0.8359\n",
            "Epoch 234/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5421 - accuracy: 0.8218 - val_loss: 0.5594 - val_accuracy: 0.8221\n",
            "Epoch 235/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5343 - accuracy: 0.8250 - val_loss: 0.5690 - val_accuracy: 0.8224\n",
            "Epoch 236/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5344 - accuracy: 0.8246 - val_loss: 0.5592 - val_accuracy: 0.8241\n",
            "Epoch 237/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5444 - accuracy: 0.8207 - val_loss: 0.5047 - val_accuracy: 0.8391\n",
            "Epoch 238/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5347 - accuracy: 0.8232 - val_loss: 0.5565 - val_accuracy: 0.8241\n",
            "Epoch 239/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5310 - accuracy: 0.8256 - val_loss: 0.5372 - val_accuracy: 0.8343\n",
            "Epoch 240/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5361 - accuracy: 0.8250 - val_loss: 0.5507 - val_accuracy: 0.8240\n",
            "Epoch 241/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5349 - accuracy: 0.8252 - val_loss: 0.5184 - val_accuracy: 0.8365\n",
            "Epoch 242/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5263 - accuracy: 0.8260 - val_loss: 0.5392 - val_accuracy: 0.8280\n",
            "Epoch 243/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5290 - accuracy: 0.8249 - val_loss: 0.5365 - val_accuracy: 0.8312\n",
            "Epoch 244/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5313 - accuracy: 0.8258 - val_loss: 0.5144 - val_accuracy: 0.8349\n",
            "Epoch 245/250\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5343 - accuracy: 0.8244 - val_loss: 0.5231 - val_accuracy: 0.8351\n",
            "Epoch 246/250\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5284 - accuracy: 0.8280 - val_loss: 0.5406 - val_accuracy: 0.8309\n",
            "Epoch 247/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5251 - accuracy: 0.8279 - val_loss: 0.5881 - val_accuracy: 0.8139\n",
            "Epoch 248/250\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5256 - accuracy: 0.8263 - val_loss: 0.5731 - val_accuracy: 0.8185\n",
            "Epoch 249/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5217 - accuracy: 0.8284 - val_loss: 0.5623 - val_accuracy: 0.8248\n",
            "Epoch 250/250\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5303 - accuracy: 0.8276 - val_loss: 0.5273 - val_accuracy: 0.8339\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.5273 - accuracy: 0.8339\n",
            "> 83.387\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "id": "4ky2G41QJeVG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}