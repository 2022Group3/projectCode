{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic model 400epochs 0.85accuracy.ipynb",
      "provenance": [],
      "mount_file_id": "1tTzvc2u2vVLkZNnm__4iJKQeIO_t2isW",
      "authorship_tag": "ABX9TyPznY3vEQw6mAQsDsQSXIzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022Group3/projectCode/blob/main/basic_model_400epochs_0_85accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "# from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "99V5KVT0PN15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def extract_zip():\n",
        "\t# load dataset\n",
        "  file=np.load(r\"drive/MyDrive/data_modified.npz\")\n",
        "  data_npz = dict(zip((\"{}\".format(k) for k in file), (file[k] for k in file)))\n",
        "\t# one hot encode target values\n",
        "\t# trainY = to_categorical(trainY)\n",
        "\t# testY = to_categorical(testY)\n",
        "  return data_npz['train'], data_npz['ytrain'], data_npz['validation'], data_npz['yvalidation'], data_npz['test'], data_npz['ytest']"
      ],
      "metadata": {
        "id": "GuTTAhRKHFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "  trainX, trainY, validationX, vlidationY, testX, testY = extract_zip()\n",
        "  return trainX, to_categorical(trainY), validationX, to_categorical(vlidationY), testX, to_categorical(testY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bmaw6xlyMHzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY, validationX, vlidationY, testX, testY = load_dataset()\n",
        "print(f'trainx= {trainX} , trainy= {trainY}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ZAJFIXC9M0",
        "outputId": "92f7754c-6f53-4783-9dd6-b49bb983f078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainx= [[[[ 21  57  95]\n",
            "   [ 21  58  98]\n",
            "   [ 20  59 101]\n",
            "   ...\n",
            "   [ 26  34  46]\n",
            "   [ 26  35  49]\n",
            "   [ 29  39  56]]\n",
            "\n",
            "  [[ 20  55  91]\n",
            "   [ 20  56  94]\n",
            "   [ 19  57  97]\n",
            "   ...\n",
            "   [ 39  44  53]\n",
            "   [ 25  33  46]\n",
            "   [ 22  35  53]]\n",
            "\n",
            "  [[ 18  52  86]\n",
            "   [ 18  53  89]\n",
            "   [ 18  55  93]\n",
            "   ...\n",
            "   [ 35  41  53]\n",
            "   [ 24  34  49]\n",
            "   [ 24  40  57]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[231 231 233]\n",
            "   [242 242 242]\n",
            "   [230 228 226]\n",
            "   ...\n",
            "   [ 27  37  41]\n",
            "   [ 29  37  37]\n",
            "   [ 30  38  44]]\n",
            "\n",
            "  [[181 178 179]\n",
            "   [209 205 203]\n",
            "   [192 187 183]\n",
            "   ...\n",
            "   [ 23  35  40]\n",
            "   [ 31  37  37]\n",
            "   [ 35  37  41]]\n",
            "\n",
            "  [[126 131 133]\n",
            "   [102 104 105]\n",
            "   [ 63  64  63]\n",
            "   ...\n",
            "   [ 25  35  46]\n",
            "   [ 32  37  42]\n",
            "   [ 35  38  44]]]\n",
            "\n",
            "\n",
            " [[[114 110 122]\n",
            "   [113 109 123]\n",
            "   [110 105 121]\n",
            "   ...\n",
            "   [ 71  72  74]\n",
            "   [ 37  36  38]\n",
            "   [ 62  61  63]]\n",
            "\n",
            "  [[116 112 122]\n",
            "   [109 105 117]\n",
            "   [113 109 122]\n",
            "   ...\n",
            "   [ 57  60  64]\n",
            "   [ 43  42  44]\n",
            "   [ 43  42  44]]\n",
            "\n",
            "  [[118 115 123]\n",
            "   [120 116 126]\n",
            "   [117 112 124]\n",
            "   ...\n",
            "   [ 44  48  54]\n",
            "   [ 47  48  50]\n",
            "   [ 45  45  47]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 62  63  69]\n",
            "   [132 144 151]\n",
            "   [ 59  78  82]\n",
            "   ...\n",
            "   [ 68  79  79]\n",
            "   [ 34  41  44]\n",
            "   [ 23  29  33]]\n",
            "\n",
            "  [[117 122 131]\n",
            "   [130 142 152]\n",
            "   [ 32  49  57]\n",
            "   ...\n",
            "   [ 93 103 103]\n",
            "   [ 83  90  93]\n",
            "   [ 37  44  48]]\n",
            "\n",
            "  [[117 126 137]\n",
            "   [107 121 133]\n",
            "   [ 35  51  61]\n",
            "   ...\n",
            "   [ 97 108 107]\n",
            "   [115 122 125]\n",
            "   [ 64  70  75]]]\n",
            "\n",
            "\n",
            " [[[ 73 100  62]\n",
            "   [ 67  96  55]\n",
            "   [ 64  99  53]\n",
            "   ...\n",
            "   [ 70 112  37]\n",
            "   [ 58  99  42]\n",
            "   [ 62 101  58]]\n",
            "\n",
            "  [[ 67  97  50]\n",
            "   [ 56  89  39]\n",
            "   [ 58  95  42]\n",
            "   ...\n",
            "   [ 68 107  45]\n",
            "   [ 60 100  49]\n",
            "   [ 67 105  64]]\n",
            "\n",
            "  [[ 60  93  36]\n",
            "   [ 53  89  31]\n",
            "   [ 57  97  38]\n",
            "   ...\n",
            "   [ 73 109  62]\n",
            "   [ 71 108  66]\n",
            "   [ 71 108  69]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[107 152 109]\n",
            "   [ 95 139  99]\n",
            "   [ 88 132  92]\n",
            "   ...\n",
            "   [ 83 121 104]\n",
            "   [122 161 141]\n",
            "   [117 159 131]]\n",
            "\n",
            "  [[117 159 111]\n",
            "   [100 142 102]\n",
            "   [ 95 138  98]\n",
            "   ...\n",
            "   [ 99 136 135]\n",
            "   [123 158 154]\n",
            "   [126 165 150]]\n",
            "\n",
            "  [[106 148  99]\n",
            "   [ 98 139  98]\n",
            "   [ 99 142 102]\n",
            "   ...\n",
            "   [117 156 155]\n",
            "   [130 171 169]\n",
            "   [139 184 170]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[224 221 216]\n",
            "   [239 237 232]\n",
            "   [248 247 244]\n",
            "   ...\n",
            "   [249 249 244]\n",
            "   [241 239 231]\n",
            "   [231 227 220]]\n",
            "\n",
            "  [[222 218 213]\n",
            "   [233 231 225]\n",
            "   [247 246 241]\n",
            "   ...\n",
            "   [249 248 243]\n",
            "   [237 235 228]\n",
            "   [228 225 218]]\n",
            "\n",
            "  [[228 226 220]\n",
            "   [236 234 229]\n",
            "   [250 249 245]\n",
            "   ...\n",
            "   [250 249 245]\n",
            "   [241 239 232]\n",
            "   [236 234 227]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 41  61  40]\n",
            "   [ 48  67  45]\n",
            "   [ 50  73  48]\n",
            "   ...\n",
            "   [ 91  99 111]\n",
            "   [ 90  99 110]\n",
            "   [ 85  93 103]]\n",
            "\n",
            "  [[ 37  58  34]\n",
            "   [ 46  69  46]\n",
            "   [ 52  80  55]\n",
            "   ...\n",
            "   [ 93 100 114]\n",
            "   [ 90  97 109]\n",
            "   [ 84  90 100]]\n",
            "\n",
            "  [[ 44  69  50]\n",
            "   [ 59  85  80]\n",
            "   [ 70  91  98]\n",
            "   ...\n",
            "   [ 92  99 113]\n",
            "   [ 89  96 108]\n",
            "   [ 84  87  98]]]\n",
            "\n",
            "\n",
            " [[[ 84 127 100]\n",
            "   [ 70 103  80]\n",
            "   [ 57  87  65]\n",
            "   ...\n",
            "   [ 69 118  86]\n",
            "   [ 61 137 100]\n",
            "   [ 64 132  98]]\n",
            "\n",
            "  [[ 84 125  98]\n",
            "   [ 74 105  81]\n",
            "   [ 65 102  77]\n",
            "   ...\n",
            "   [ 69 138 100]\n",
            "   [ 71 143 109]\n",
            "   [ 72 135 102]]\n",
            "\n",
            "  [[ 75 109  83]\n",
            "   [ 67  98  73]\n",
            "   [ 67 118  90]\n",
            "   ...\n",
            "   [ 66 138 102]\n",
            "   [ 82 141 111]\n",
            "   [ 80 134 103]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 57 101 139]\n",
            "   [ 68 111 148]\n",
            "   [ 85 122 155]\n",
            "   ...\n",
            "   [ 99 187 149]\n",
            "   [ 99 187 146]\n",
            "   [ 96 186 145]]\n",
            "\n",
            "  [[ 66 111 151]\n",
            "   [ 68 111 150]\n",
            "   [ 97 132 162]\n",
            "   ...\n",
            "   [ 99 190 153]\n",
            "   [102 190 151]\n",
            "   [103 191 151]]\n",
            "\n",
            "  [[ 74 114 147]\n",
            "   [ 78 114 146]\n",
            "   [129 157 179]\n",
            "   ...\n",
            "   [100 189 150]\n",
            "   [100 187 148]\n",
            "   [103 186 147]]]\n",
            "\n",
            "\n",
            " [[[  1   0   0]\n",
            "   [  5   7   7]\n",
            "   [ 54  63  69]\n",
            "   ...\n",
            "   [119 144 148]\n",
            "   [ 96 128 134]\n",
            "   [ 85 122 130]]\n",
            "\n",
            "  [[  1   0   0]\n",
            "   [  5  10   9]\n",
            "   [ 85  96 102]\n",
            "   ...\n",
            "   [134 148 156]\n",
            "   [102 125 135]\n",
            "   [ 74 107 115]]\n",
            "\n",
            "  [[  1   0   0]\n",
            "   [  5   8   8]\n",
            "   [ 93  99 104]\n",
            "   ...\n",
            "   [171 175 182]\n",
            "   [164 169 177]\n",
            "   [147 157 164]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[217 226 233]\n",
            "   [177 189 201]\n",
            "   [158 173 186]\n",
            "   ...\n",
            "   [238 241 246]\n",
            "   [238 241 246]\n",
            "   [240 243 248]]\n",
            "\n",
            "  [[219 227 234]\n",
            "   [197 207 220]\n",
            "   [168 190 203]\n",
            "   ...\n",
            "   [238 241 246]\n",
            "   [238 241 245]\n",
            "   [241 244 248]]\n",
            "\n",
            "  [[234 238 244]\n",
            "   [224 229 237]\n",
            "   [208 219 227]\n",
            "   ...\n",
            "   [240 242 243]\n",
            "   [239 241 243]\n",
            "   [243 245 246]]]] , trainy= [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPctj-ajNyj2"
      },
      "outputs": [],
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(16, activation='softmax'))\n",
        " \t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "IE81FEJBO0lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()"
      ],
      "metadata": {
        "id": "cAupcXLUO1-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY,validationX, vlidationY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=400, validation_data=(validationX, vlidationY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "RsRQH6orD4cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-7HW3ZNRv6X",
        "outputId": "d488c325-8a89-4bfa-8030-bd42a1d292dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "703/703 [==============================] - 37s 34ms/step - loss: 2.6803 - accuracy: 0.2269 - val_loss: 1060.0331 - val_accuracy: 0.0673\n",
            "Epoch 2/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 2.0718 - accuracy: 0.3281 - val_loss: 924.6054 - val_accuracy: 0.0713\n",
            "Epoch 3/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 1.9149 - accuracy: 0.3708 - val_loss: 688.1144 - val_accuracy: 0.1168\n",
            "Epoch 4/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.8163 - accuracy: 0.4001 - val_loss: 613.9727 - val_accuracy: 0.1049\n",
            "Epoch 5/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.7538 - accuracy: 0.4201 - val_loss: 634.7299 - val_accuracy: 0.1001\n",
            "Epoch 6/400\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 1.6939 - accuracy: 0.4424 - val_loss: 552.9687 - val_accuracy: 0.1069\n",
            "Epoch 7/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 1.6338 - accuracy: 0.4597 - val_loss: 533.5683 - val_accuracy: 0.1189\n",
            "Epoch 8/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.5835 - accuracy: 0.4789 - val_loss: 477.0487 - val_accuracy: 0.1136\n",
            "Epoch 9/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 1.5361 - accuracy: 0.4904 - val_loss: 492.0676 - val_accuracy: 0.1267\n",
            "Epoch 10/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.4961 - accuracy: 0.5074 - val_loss: 509.9221 - val_accuracy: 0.1368\n",
            "Epoch 11/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 1.4591 - accuracy: 0.5168 - val_loss: 490.0655 - val_accuracy: 0.1395\n",
            "Epoch 12/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 1.4238 - accuracy: 0.5318 - val_loss: 489.0034 - val_accuracy: 0.1359\n",
            "Epoch 13/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 1.4002 - accuracy: 0.5420 - val_loss: 520.5035 - val_accuracy: 0.1331\n",
            "Epoch 14/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.3708 - accuracy: 0.5498 - val_loss: 469.4881 - val_accuracy: 0.1427\n",
            "Epoch 15/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.3439 - accuracy: 0.5585 - val_loss: 512.7045 - val_accuracy: 0.1227\n",
            "Epoch 16/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.3245 - accuracy: 0.5656 - val_loss: 518.9362 - val_accuracy: 0.1197\n",
            "Epoch 17/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.3018 - accuracy: 0.5723 - val_loss: 496.4163 - val_accuracy: 0.1167\n",
            "Epoch 18/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2827 - accuracy: 0.5771 - val_loss: 526.0287 - val_accuracy: 0.1013\n",
            "Epoch 19/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.2628 - accuracy: 0.5849 - val_loss: 522.3502 - val_accuracy: 0.1155\n",
            "Epoch 20/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.2485 - accuracy: 0.5889 - val_loss: 552.3719 - val_accuracy: 0.0944\n",
            "Epoch 21/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2343 - accuracy: 0.5940 - val_loss: 537.3350 - val_accuracy: 0.0784\n",
            "Epoch 22/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2204 - accuracy: 0.5978 - val_loss: 546.4289 - val_accuracy: 0.0876\n",
            "Epoch 23/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2069 - accuracy: 0.6010 - val_loss: 591.4404 - val_accuracy: 0.0948\n",
            "Epoch 24/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1852 - accuracy: 0.6082 - val_loss: 529.3198 - val_accuracy: 0.1009\n",
            "Epoch 25/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1768 - accuracy: 0.6160 - val_loss: 534.3508 - val_accuracy: 0.0779\n",
            "Epoch 26/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1660 - accuracy: 0.6162 - val_loss: 487.9043 - val_accuracy: 0.0879\n",
            "Epoch 27/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 1.1482 - accuracy: 0.6216 - val_loss: 532.9695 - val_accuracy: 0.1015\n",
            "Epoch 28/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1412 - accuracy: 0.6255 - val_loss: 565.0485 - val_accuracy: 0.0711\n",
            "Epoch 29/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1233 - accuracy: 0.6311 - val_loss: 509.7087 - val_accuracy: 0.0787\n",
            "Epoch 30/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.1223 - accuracy: 0.6302 - val_loss: 492.9704 - val_accuracy: 0.0895\n",
            "Epoch 31/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 1.1045 - accuracy: 0.6366 - val_loss: 535.0642 - val_accuracy: 0.0671\n",
            "Epoch 32/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0991 - accuracy: 0.6390 - val_loss: 530.3069 - val_accuracy: 0.0720\n",
            "Epoch 33/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0868 - accuracy: 0.6423 - val_loss: 494.4713 - val_accuracy: 0.0683\n",
            "Epoch 34/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0731 - accuracy: 0.6474 - val_loss: 478.4531 - val_accuracy: 0.0760\n",
            "Epoch 35/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0689 - accuracy: 0.6486 - val_loss: 431.4310 - val_accuracy: 0.0647\n",
            "Epoch 36/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0584 - accuracy: 0.6496 - val_loss: 439.0677 - val_accuracy: 0.0781\n",
            "Epoch 37/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0549 - accuracy: 0.6534 - val_loss: 432.1326 - val_accuracy: 0.0784\n",
            "Epoch 38/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0459 - accuracy: 0.6561 - val_loss: 460.0358 - val_accuracy: 0.0653\n",
            "Epoch 39/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0285 - accuracy: 0.6628 - val_loss: 418.5681 - val_accuracy: 0.0921\n",
            "Epoch 40/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 1.0269 - accuracy: 0.6617 - val_loss: 392.8336 - val_accuracy: 0.0821\n",
            "Epoch 41/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0182 - accuracy: 0.6649 - val_loss: 428.6862 - val_accuracy: 0.0792\n",
            "Epoch 42/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0100 - accuracy: 0.6660 - val_loss: 419.4907 - val_accuracy: 0.0608\n",
            "Epoch 43/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 1.0000 - accuracy: 0.6709 - val_loss: 423.8303 - val_accuracy: 0.0872\n",
            "Epoch 44/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.9994 - accuracy: 0.6721 - val_loss: 426.2650 - val_accuracy: 0.0765\n",
            "Epoch 45/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9905 - accuracy: 0.6741 - val_loss: 397.6902 - val_accuracy: 0.0828\n",
            "Epoch 46/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9895 - accuracy: 0.6745 - val_loss: 421.6857 - val_accuracy: 0.0813\n",
            "Epoch 47/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9731 - accuracy: 0.6802 - val_loss: 417.0937 - val_accuracy: 0.0873\n",
            "Epoch 48/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9621 - accuracy: 0.6824 - val_loss: 389.3016 - val_accuracy: 0.1273\n",
            "Epoch 49/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9600 - accuracy: 0.6832 - val_loss: 370.7569 - val_accuracy: 0.0843\n",
            "Epoch 50/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9523 - accuracy: 0.6879 - val_loss: 384.6848 - val_accuracy: 0.0819\n",
            "Epoch 51/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.9493 - accuracy: 0.6867 - val_loss: 339.7298 - val_accuracy: 0.1227\n",
            "Epoch 52/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9426 - accuracy: 0.6909 - val_loss: 334.1953 - val_accuracy: 0.1505\n",
            "Epoch 53/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9396 - accuracy: 0.6923 - val_loss: 380.5412 - val_accuracy: 0.0969\n",
            "Epoch 54/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9365 - accuracy: 0.6933 - val_loss: 386.7669 - val_accuracy: 0.0781\n",
            "Epoch 55/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9258 - accuracy: 0.6966 - val_loss: 370.2873 - val_accuracy: 0.1212\n",
            "Epoch 56/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.9192 - accuracy: 0.7003 - val_loss: 376.1469 - val_accuracy: 0.0819\n",
            "Epoch 57/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9156 - accuracy: 0.7008 - val_loss: 350.1155 - val_accuracy: 0.1167\n",
            "Epoch 58/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.9044 - accuracy: 0.7003 - val_loss: 360.7732 - val_accuracy: 0.1115\n",
            "Epoch 59/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.9047 - accuracy: 0.7044 - val_loss: 358.2333 - val_accuracy: 0.0968\n",
            "Epoch 60/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8949 - accuracy: 0.7068 - val_loss: 350.9679 - val_accuracy: 0.0879\n",
            "Epoch 61/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.8975 - accuracy: 0.7030 - val_loss: 298.0815 - val_accuracy: 0.1116\n",
            "Epoch 62/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8851 - accuracy: 0.7077 - val_loss: 327.2206 - val_accuracy: 0.1047\n",
            "Epoch 63/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.8795 - accuracy: 0.7120 - val_loss: 295.3837 - val_accuracy: 0.1148\n",
            "Epoch 64/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.8805 - accuracy: 0.7110 - val_loss: 306.8083 - val_accuracy: 0.1383\n",
            "Epoch 65/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8755 - accuracy: 0.7151 - val_loss: 309.9931 - val_accuracy: 0.1209\n",
            "Epoch 66/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8636 - accuracy: 0.7167 - val_loss: 331.8411 - val_accuracy: 0.0873\n",
            "Epoch 67/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.8644 - accuracy: 0.7174 - val_loss: 321.7784 - val_accuracy: 0.0959\n",
            "Epoch 68/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8639 - accuracy: 0.7180 - val_loss: 322.7843 - val_accuracy: 0.1085\n",
            "Epoch 69/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.8542 - accuracy: 0.7216 - val_loss: 305.9855 - val_accuracy: 0.0947\n",
            "Epoch 70/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8486 - accuracy: 0.7214 - val_loss: 332.5884 - val_accuracy: 0.1267\n",
            "Epoch 71/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.8482 - accuracy: 0.7230 - val_loss: 283.9146 - val_accuracy: 0.1008\n",
            "Epoch 72/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8352 - accuracy: 0.7267 - val_loss: 311.0529 - val_accuracy: 0.1331\n",
            "Epoch 73/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8381 - accuracy: 0.7245 - val_loss: 356.6314 - val_accuracy: 0.0987\n",
            "Epoch 74/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.8364 - accuracy: 0.7289 - val_loss: 343.8615 - val_accuracy: 0.1140\n",
            "Epoch 75/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8238 - accuracy: 0.7318 - val_loss: 368.5688 - val_accuracy: 0.1119\n",
            "Epoch 76/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8225 - accuracy: 0.7296 - val_loss: 277.5271 - val_accuracy: 0.1392\n",
            "Epoch 77/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.8171 - accuracy: 0.7325 - val_loss: 316.5575 - val_accuracy: 0.1193\n",
            "Epoch 78/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.8158 - accuracy: 0.7324 - val_loss: 330.3141 - val_accuracy: 0.1109\n",
            "Epoch 79/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8209 - accuracy: 0.7301 - val_loss: 314.6354 - val_accuracy: 0.1331\n",
            "Epoch 80/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8098 - accuracy: 0.7336 - val_loss: 279.1507 - val_accuracy: 0.1063\n",
            "Epoch 81/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.8088 - accuracy: 0.7356 - val_loss: 265.6712 - val_accuracy: 0.1467\n",
            "Epoch 82/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8046 - accuracy: 0.7384 - val_loss: 230.4243 - val_accuracy: 0.1284\n",
            "Epoch 83/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.7999 - accuracy: 0.7384 - val_loss: 239.7291 - val_accuracy: 0.1129\n",
            "Epoch 84/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.7991 - accuracy: 0.7411 - val_loss: 287.6415 - val_accuracy: 0.0947\n",
            "Epoch 85/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.7901 - accuracy: 0.7406 - val_loss: 280.6690 - val_accuracy: 0.1124\n",
            "Epoch 86/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7876 - accuracy: 0.7413 - val_loss: 333.5982 - val_accuracy: 0.0976\n",
            "Epoch 87/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7820 - accuracy: 0.7447 - val_loss: 282.1329 - val_accuracy: 0.1440\n",
            "Epoch 88/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7831 - accuracy: 0.7457 - val_loss: 330.4984 - val_accuracy: 0.1163\n",
            "Epoch 89/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.7824 - accuracy: 0.7432 - val_loss: 302.1239 - val_accuracy: 0.1143\n",
            "Epoch 90/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7801 - accuracy: 0.7453 - val_loss: 243.3672 - val_accuracy: 0.1443\n",
            "Epoch 91/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7746 - accuracy: 0.7468 - val_loss: 313.6751 - val_accuracy: 0.1271\n",
            "Epoch 92/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.7645 - accuracy: 0.7509 - val_loss: 311.8877 - val_accuracy: 0.1223\n",
            "Epoch 93/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.7612 - accuracy: 0.7511 - val_loss: 300.7490 - val_accuracy: 0.1253\n",
            "Epoch 94/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.7601 - accuracy: 0.7542 - val_loss: 293.9023 - val_accuracy: 0.1253\n",
            "Epoch 95/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7617 - accuracy: 0.7509 - val_loss: 288.8387 - val_accuracy: 0.1313\n",
            "Epoch 96/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7583 - accuracy: 0.7541 - val_loss: 245.0883 - val_accuracy: 0.1509\n",
            "Epoch 97/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.7541 - accuracy: 0.7516 - val_loss: 296.9974 - val_accuracy: 0.1177\n",
            "Epoch 98/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7499 - accuracy: 0.7534 - val_loss: 261.9380 - val_accuracy: 0.1515\n",
            "Epoch 99/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7424 - accuracy: 0.7562 - val_loss: 250.8872 - val_accuracy: 0.1587\n",
            "Epoch 100/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7459 - accuracy: 0.7551 - val_loss: 235.2858 - val_accuracy: 0.1304\n",
            "Epoch 101/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.7396 - accuracy: 0.7591 - val_loss: 257.3567 - val_accuracy: 0.1241\n",
            "Epoch 102/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.7391 - accuracy: 0.7571 - val_loss: 272.7477 - val_accuracy: 0.1352\n",
            "Epoch 103/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7349 - accuracy: 0.7585 - val_loss: 268.6952 - val_accuracy: 0.1091\n",
            "Epoch 104/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7333 - accuracy: 0.7609 - val_loss: 295.5100 - val_accuracy: 0.1240\n",
            "Epoch 105/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7306 - accuracy: 0.7614 - val_loss: 304.8992 - val_accuracy: 0.0971\n",
            "Epoch 106/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.7264 - accuracy: 0.7624 - val_loss: 270.2935 - val_accuracy: 0.0929\n",
            "Epoch 107/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7238 - accuracy: 0.7630 - val_loss: 271.8299 - val_accuracy: 0.1259\n",
            "Epoch 108/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7233 - accuracy: 0.7618 - val_loss: 275.4976 - val_accuracy: 0.1243\n",
            "Epoch 109/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7252 - accuracy: 0.7618 - val_loss: 296.8341 - val_accuracy: 0.1136\n",
            "Epoch 110/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.7181 - accuracy: 0.7645 - val_loss: 281.6114 - val_accuracy: 0.1171\n",
            "Epoch 111/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7151 - accuracy: 0.7663 - val_loss: 299.1593 - val_accuracy: 0.1108\n",
            "Epoch 112/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7115 - accuracy: 0.7662 - val_loss: 247.6568 - val_accuracy: 0.1199\n",
            "Epoch 113/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.7045 - accuracy: 0.7709 - val_loss: 327.5975 - val_accuracy: 0.1079\n",
            "Epoch 114/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7074 - accuracy: 0.7678 - val_loss: 295.2927 - val_accuracy: 0.1111\n",
            "Epoch 115/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7046 - accuracy: 0.7683 - val_loss: 278.4042 - val_accuracy: 0.1171\n",
            "Epoch 116/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.7039 - accuracy: 0.7696 - val_loss: 316.7640 - val_accuracy: 0.1177\n",
            "Epoch 117/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6953 - accuracy: 0.7726 - val_loss: 282.4691 - val_accuracy: 0.1037\n",
            "Epoch 118/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6930 - accuracy: 0.7730 - val_loss: 315.3417 - val_accuracy: 0.0885\n",
            "Epoch 119/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6968 - accuracy: 0.7730 - val_loss: 295.4085 - val_accuracy: 0.1021\n",
            "Epoch 120/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.6969 - accuracy: 0.7704 - val_loss: 295.8200 - val_accuracy: 0.1024\n",
            "Epoch 121/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6872 - accuracy: 0.7776 - val_loss: 294.9808 - val_accuracy: 0.1007\n",
            "Epoch 122/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.6841 - accuracy: 0.7757 - val_loss: 260.0233 - val_accuracy: 0.1109\n",
            "Epoch 123/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6898 - accuracy: 0.7757 - val_loss: 241.1231 - val_accuracy: 0.1383\n",
            "Epoch 124/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.6820 - accuracy: 0.7777 - val_loss: 296.7093 - val_accuracy: 0.1056\n",
            "Epoch 125/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.6793 - accuracy: 0.7762 - val_loss: 295.2892 - val_accuracy: 0.1128\n",
            "Epoch 126/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6857 - accuracy: 0.7745 - val_loss: 240.7408 - val_accuracy: 0.1148\n",
            "Epoch 127/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6735 - accuracy: 0.7784 - val_loss: 220.8664 - val_accuracy: 0.1245\n",
            "Epoch 128/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6767 - accuracy: 0.7795 - val_loss: 248.2664 - val_accuracy: 0.1048\n",
            "Epoch 129/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6691 - accuracy: 0.7781 - val_loss: 282.4077 - val_accuracy: 0.1057\n",
            "Epoch 130/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6723 - accuracy: 0.7795 - val_loss: 282.0828 - val_accuracy: 0.0959\n",
            "Epoch 131/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.6691 - accuracy: 0.7824 - val_loss: 255.4580 - val_accuracy: 0.1293\n",
            "Epoch 132/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6660 - accuracy: 0.7833 - val_loss: 223.1812 - val_accuracy: 0.1117\n",
            "Epoch 133/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6685 - accuracy: 0.7816 - val_loss: 251.3835 - val_accuracy: 0.1027\n",
            "Epoch 134/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6628 - accuracy: 0.7839 - val_loss: 258.6721 - val_accuracy: 0.1005\n",
            "Epoch 135/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6619 - accuracy: 0.7844 - val_loss: 253.9991 - val_accuracy: 0.1052\n",
            "Epoch 136/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6579 - accuracy: 0.7852 - val_loss: 248.5799 - val_accuracy: 0.1016\n",
            "Epoch 137/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6560 - accuracy: 0.7861 - val_loss: 269.8556 - val_accuracy: 0.0981\n",
            "Epoch 138/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6600 - accuracy: 0.7831 - val_loss: 262.3721 - val_accuracy: 0.1024\n",
            "Epoch 139/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6548 - accuracy: 0.7860 - val_loss: 244.7393 - val_accuracy: 0.1009\n",
            "Epoch 140/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6518 - accuracy: 0.7848 - val_loss: 237.1262 - val_accuracy: 0.0940\n",
            "Epoch 141/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6495 - accuracy: 0.7884 - val_loss: 218.2767 - val_accuracy: 0.1160\n",
            "Epoch 142/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6469 - accuracy: 0.7894 - val_loss: 198.8340 - val_accuracy: 0.1259\n",
            "Epoch 143/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6442 - accuracy: 0.7887 - val_loss: 221.7059 - val_accuracy: 0.1048\n",
            "Epoch 144/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6451 - accuracy: 0.7897 - val_loss: 221.1967 - val_accuracy: 0.1121\n",
            "Epoch 145/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6407 - accuracy: 0.7899 - val_loss: 249.9780 - val_accuracy: 0.1143\n",
            "Epoch 146/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.6420 - accuracy: 0.7901 - val_loss: 256.9227 - val_accuracy: 0.1144\n",
            "Epoch 147/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6454 - accuracy: 0.7904 - val_loss: 228.7727 - val_accuracy: 0.1185\n",
            "Epoch 148/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6298 - accuracy: 0.7938 - val_loss: 259.0628 - val_accuracy: 0.1164\n",
            "Epoch 149/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.6383 - accuracy: 0.7912 - val_loss: 226.1726 - val_accuracy: 0.0983\n",
            "Epoch 150/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6342 - accuracy: 0.7940 - val_loss: 243.6930 - val_accuracy: 0.1068\n",
            "Epoch 151/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6337 - accuracy: 0.7926 - val_loss: 255.7950 - val_accuracy: 0.0863\n",
            "Epoch 152/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.6265 - accuracy: 0.7933 - val_loss: 278.7076 - val_accuracy: 0.0956\n",
            "Epoch 153/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6277 - accuracy: 0.7940 - val_loss: 232.6071 - val_accuracy: 0.1093\n",
            "Epoch 154/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6244 - accuracy: 0.7958 - val_loss: 229.4812 - val_accuracy: 0.1177\n",
            "Epoch 155/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6257 - accuracy: 0.7955 - val_loss: 232.5038 - val_accuracy: 0.0995\n",
            "Epoch 156/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6243 - accuracy: 0.7949 - val_loss: 195.3600 - val_accuracy: 0.1288\n",
            "Epoch 157/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6215 - accuracy: 0.7973 - val_loss: 189.4336 - val_accuracy: 0.1281\n",
            "Epoch 158/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.6213 - accuracy: 0.7958 - val_loss: 203.2971 - val_accuracy: 0.1297\n",
            "Epoch 159/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.6188 - accuracy: 0.7980 - val_loss: 226.9355 - val_accuracy: 0.1241\n",
            "Epoch 160/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6140 - accuracy: 0.7970 - val_loss: 218.5795 - val_accuracy: 0.1187\n",
            "Epoch 161/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6147 - accuracy: 0.8001 - val_loss: 199.7004 - val_accuracy: 0.1311\n",
            "Epoch 162/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6152 - accuracy: 0.7988 - val_loss: 244.9181 - val_accuracy: 0.1188\n",
            "Epoch 163/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6136 - accuracy: 0.8001 - val_loss: 249.7569 - val_accuracy: 0.0997\n",
            "Epoch 164/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.6106 - accuracy: 0.7982 - val_loss: 259.1662 - val_accuracy: 0.1047\n",
            "Epoch 165/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6030 - accuracy: 0.8027 - val_loss: 252.4738 - val_accuracy: 0.1156\n",
            "Epoch 166/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6012 - accuracy: 0.8035 - val_loss: 219.3151 - val_accuracy: 0.1297\n",
            "Epoch 167/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6060 - accuracy: 0.8009 - val_loss: 250.9367 - val_accuracy: 0.1057\n",
            "Epoch 168/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6004 - accuracy: 0.8039 - val_loss: 196.8541 - val_accuracy: 0.1096\n",
            "Epoch 169/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6017 - accuracy: 0.8022 - val_loss: 203.3716 - val_accuracy: 0.1491\n",
            "Epoch 170/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5989 - accuracy: 0.8063 - val_loss: 219.5263 - val_accuracy: 0.1316\n",
            "Epoch 171/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6004 - accuracy: 0.8022 - val_loss: 238.3783 - val_accuracy: 0.1197\n",
            "Epoch 172/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.6030 - accuracy: 0.8034 - val_loss: 180.1847 - val_accuracy: 0.1204\n",
            "Epoch 173/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.5977 - accuracy: 0.8039 - val_loss: 240.8096 - val_accuracy: 0.1179\n",
            "Epoch 174/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5950 - accuracy: 0.8047 - val_loss: 203.0274 - val_accuracy: 0.1215\n",
            "Epoch 175/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5930 - accuracy: 0.8068 - val_loss: 191.1007 - val_accuracy: 0.1248\n",
            "Epoch 176/400\n",
            "703/703 [==============================] - 23s 32ms/step - loss: 0.5977 - accuracy: 0.8033 - val_loss: 189.6140 - val_accuracy: 0.1460\n",
            "Epoch 177/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5968 - accuracy: 0.8041 - val_loss: 198.9394 - val_accuracy: 0.1396\n",
            "Epoch 178/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5864 - accuracy: 0.8078 - val_loss: 206.3092 - val_accuracy: 0.1356\n",
            "Epoch 179/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5870 - accuracy: 0.8083 - val_loss: 260.5182 - val_accuracy: 0.0941\n",
            "Epoch 180/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5844 - accuracy: 0.8090 - val_loss: 204.2483 - val_accuracy: 0.1231\n",
            "Epoch 181/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5880 - accuracy: 0.8073 - val_loss: 270.7737 - val_accuracy: 0.1043\n",
            "Epoch 182/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5852 - accuracy: 0.8090 - val_loss: 242.0849 - val_accuracy: 0.1160\n",
            "Epoch 183/400\n",
            "703/703 [==============================] - 24s 33ms/step - loss: 0.5849 - accuracy: 0.8083 - val_loss: 237.7997 - val_accuracy: 0.1187\n",
            "Epoch 184/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5771 - accuracy: 0.8104 - val_loss: 197.4111 - val_accuracy: 0.1345\n",
            "Epoch 185/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5798 - accuracy: 0.8102 - val_loss: 217.8416 - val_accuracy: 0.1063\n",
            "Epoch 186/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5770 - accuracy: 0.8099 - val_loss: 233.2092 - val_accuracy: 0.1132\n",
            "Epoch 187/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5781 - accuracy: 0.8107 - val_loss: 204.9795 - val_accuracy: 0.1271\n",
            "Epoch 188/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5786 - accuracy: 0.8103 - val_loss: 210.6739 - val_accuracy: 0.1324\n",
            "Epoch 189/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5695 - accuracy: 0.8146 - val_loss: 205.1869 - val_accuracy: 0.1487\n",
            "Epoch 190/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5701 - accuracy: 0.8145 - val_loss: 200.0580 - val_accuracy: 0.1295\n",
            "Epoch 191/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5724 - accuracy: 0.8128 - val_loss: 212.9437 - val_accuracy: 0.1101\n",
            "Epoch 192/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5775 - accuracy: 0.8131 - val_loss: 191.0788 - val_accuracy: 0.1353\n",
            "Epoch 193/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5718 - accuracy: 0.8102 - val_loss: 177.2467 - val_accuracy: 0.1303\n",
            "Epoch 194/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5642 - accuracy: 0.8150 - val_loss: 225.4631 - val_accuracy: 0.1261\n",
            "Epoch 195/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5621 - accuracy: 0.8168 - val_loss: 168.0549 - val_accuracy: 0.1552\n",
            "Epoch 196/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5654 - accuracy: 0.8142 - val_loss: 191.3911 - val_accuracy: 0.1228\n",
            "Epoch 197/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5593 - accuracy: 0.8157 - val_loss: 205.1504 - val_accuracy: 0.1313\n",
            "Epoch 198/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5665 - accuracy: 0.8132 - val_loss: 199.8509 - val_accuracy: 0.1337\n",
            "Epoch 199/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5656 - accuracy: 0.8149 - val_loss: 208.4435 - val_accuracy: 0.1156\n",
            "Epoch 200/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5591 - accuracy: 0.8160 - val_loss: 188.0919 - val_accuracy: 0.1385\n",
            "Epoch 201/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5627 - accuracy: 0.8169 - val_loss: 202.4335 - val_accuracy: 0.1116\n",
            "Epoch 202/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5652 - accuracy: 0.8160 - val_loss: 215.8445 - val_accuracy: 0.1156\n",
            "Epoch 203/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5588 - accuracy: 0.8183 - val_loss: 214.2640 - val_accuracy: 0.1255\n",
            "Epoch 204/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5542 - accuracy: 0.8201 - val_loss: 171.8073 - val_accuracy: 0.1511\n",
            "Epoch 205/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5566 - accuracy: 0.8181 - val_loss: 193.0354 - val_accuracy: 0.1356\n",
            "Epoch 206/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5609 - accuracy: 0.8166 - val_loss: 177.1088 - val_accuracy: 0.1589\n",
            "Epoch 207/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5559 - accuracy: 0.8180 - val_loss: 224.5857 - val_accuracy: 0.1260\n",
            "Epoch 208/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5505 - accuracy: 0.8193 - val_loss: 204.8734 - val_accuracy: 0.1220\n",
            "Epoch 209/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5546 - accuracy: 0.8188 - val_loss: 185.8238 - val_accuracy: 0.1429\n",
            "Epoch 210/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5493 - accuracy: 0.8188 - val_loss: 249.1379 - val_accuracy: 0.1208\n",
            "Epoch 211/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5513 - accuracy: 0.8195 - val_loss: 185.5934 - val_accuracy: 0.1521\n",
            "Epoch 212/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5539 - accuracy: 0.8183 - val_loss: 193.1027 - val_accuracy: 0.1436\n",
            "Epoch 213/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5481 - accuracy: 0.8187 - val_loss: 181.8245 - val_accuracy: 0.1307\n",
            "Epoch 214/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5494 - accuracy: 0.8214 - val_loss: 194.2188 - val_accuracy: 0.1305\n",
            "Epoch 215/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.5461 - accuracy: 0.8214 - val_loss: 189.0253 - val_accuracy: 0.1523\n",
            "Epoch 216/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5457 - accuracy: 0.8205 - val_loss: 213.3075 - val_accuracy: 0.1339\n",
            "Epoch 217/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5444 - accuracy: 0.8230 - val_loss: 200.9693 - val_accuracy: 0.1381\n",
            "Epoch 218/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5435 - accuracy: 0.8233 - val_loss: 209.5486 - val_accuracy: 0.1244\n",
            "Epoch 219/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5408 - accuracy: 0.8217 - val_loss: 193.0282 - val_accuracy: 0.1519\n",
            "Epoch 220/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5411 - accuracy: 0.8218 - val_loss: 196.0622 - val_accuracy: 0.1395\n",
            "Epoch 221/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5403 - accuracy: 0.8223 - val_loss: 158.9859 - val_accuracy: 0.1768\n",
            "Epoch 222/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5399 - accuracy: 0.8231 - val_loss: 164.2102 - val_accuracy: 0.1572\n",
            "Epoch 223/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5348 - accuracy: 0.8234 - val_loss: 144.2877 - val_accuracy: 0.1697\n",
            "Epoch 224/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5344 - accuracy: 0.8248 - val_loss: 167.6232 - val_accuracy: 0.1384\n",
            "Epoch 225/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5325 - accuracy: 0.8230 - val_loss: 171.3801 - val_accuracy: 0.1489\n",
            "Epoch 226/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5360 - accuracy: 0.8238 - val_loss: 178.3008 - val_accuracy: 0.1531\n",
            "Epoch 227/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5283 - accuracy: 0.8254 - val_loss: 177.2896 - val_accuracy: 0.1423\n",
            "Epoch 228/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5309 - accuracy: 0.8260 - val_loss: 196.6244 - val_accuracy: 0.1229\n",
            "Epoch 229/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5292 - accuracy: 0.8245 - val_loss: 205.8061 - val_accuracy: 0.1236\n",
            "Epoch 230/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5303 - accuracy: 0.8238 - val_loss: 177.1559 - val_accuracy: 0.1331\n",
            "Epoch 231/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5286 - accuracy: 0.8259 - val_loss: 205.2555 - val_accuracy: 0.1221\n",
            "Epoch 232/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5309 - accuracy: 0.8239 - val_loss: 190.5197 - val_accuracy: 0.1328\n",
            "Epoch 233/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5278 - accuracy: 0.8263 - val_loss: 160.3201 - val_accuracy: 0.1268\n",
            "Epoch 234/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5267 - accuracy: 0.8262 - val_loss: 183.9499 - val_accuracy: 0.1425\n",
            "Epoch 235/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5231 - accuracy: 0.8285 - val_loss: 189.6818 - val_accuracy: 0.1232\n",
            "Epoch 236/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5262 - accuracy: 0.8263 - val_loss: 164.5680 - val_accuracy: 0.1324\n",
            "Epoch 237/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5266 - accuracy: 0.8252 - val_loss: 197.5234 - val_accuracy: 0.1293\n",
            "Epoch 238/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5244 - accuracy: 0.8278 - val_loss: 172.9845 - val_accuracy: 0.1363\n",
            "Epoch 239/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5156 - accuracy: 0.8303 - val_loss: 181.9585 - val_accuracy: 0.1493\n",
            "Epoch 240/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5259 - accuracy: 0.8253 - val_loss: 178.6492 - val_accuracy: 0.1213\n",
            "Epoch 241/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5189 - accuracy: 0.8296 - val_loss: 187.0521 - val_accuracy: 0.1395\n",
            "Epoch 242/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5226 - accuracy: 0.8284 - val_loss: 193.5398 - val_accuracy: 0.1235\n",
            "Epoch 243/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5173 - accuracy: 0.8308 - val_loss: 195.8703 - val_accuracy: 0.1355\n",
            "Epoch 244/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5155 - accuracy: 0.8305 - val_loss: 198.4549 - val_accuracy: 0.1132\n",
            "Epoch 245/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5179 - accuracy: 0.8286 - val_loss: 175.0194 - val_accuracy: 0.1273\n",
            "Epoch 246/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5195 - accuracy: 0.8273 - val_loss: 189.2473 - val_accuracy: 0.1327\n",
            "Epoch 247/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5434 - accuracy: 0.8210 - val_loss: 175.6404 - val_accuracy: 0.1492\n",
            "Epoch 248/400\n",
            "703/703 [==============================] - 23s 33ms/step - loss: 0.5220 - accuracy: 0.8283 - val_loss: 217.0051 - val_accuracy: 0.1252\n",
            "Epoch 249/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5184 - accuracy: 0.8294 - val_loss: 196.9214 - val_accuracy: 0.1216\n",
            "Epoch 250/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5191 - accuracy: 0.8289 - val_loss: 177.6618 - val_accuracy: 0.1293\n",
            "Epoch 251/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.5138 - accuracy: 0.8313 - val_loss: 198.8916 - val_accuracy: 0.1212\n",
            "Epoch 252/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5078 - accuracy: 0.8333 - val_loss: 197.1837 - val_accuracy: 0.1347\n",
            "Epoch 253/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5115 - accuracy: 0.8321 - val_loss: 166.4582 - val_accuracy: 0.1479\n",
            "Epoch 254/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.5120 - accuracy: 0.8306 - val_loss: 193.0883 - val_accuracy: 0.1236\n",
            "Epoch 255/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5085 - accuracy: 0.8312 - val_loss: 172.7827 - val_accuracy: 0.1272\n",
            "Epoch 256/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5040 - accuracy: 0.8348 - val_loss: 152.3362 - val_accuracy: 0.1517\n",
            "Epoch 257/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4979 - accuracy: 0.8364 - val_loss: 217.2627 - val_accuracy: 0.1212\n",
            "Epoch 258/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5028 - accuracy: 0.8334 - val_loss: 220.4598 - val_accuracy: 0.1211\n",
            "Epoch 259/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5084 - accuracy: 0.8308 - val_loss: 201.0434 - val_accuracy: 0.1108\n",
            "Epoch 260/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.5039 - accuracy: 0.8343 - val_loss: 202.5894 - val_accuracy: 0.1448\n",
            "Epoch 261/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5037 - accuracy: 0.8353 - val_loss: 196.8576 - val_accuracy: 0.1345\n",
            "Epoch 262/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.5159 - accuracy: 0.8311 - val_loss: 160.5354 - val_accuracy: 0.1381\n",
            "Epoch 263/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5010 - accuracy: 0.8348 - val_loss: 199.7634 - val_accuracy: 0.1101\n",
            "Epoch 264/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.5010 - accuracy: 0.8348 - val_loss: 196.9137 - val_accuracy: 0.1207\n",
            "Epoch 265/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4957 - accuracy: 0.8373 - val_loss: 186.1156 - val_accuracy: 0.1277\n",
            "Epoch 266/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5012 - accuracy: 0.8358 - val_loss: 161.2134 - val_accuracy: 0.1499\n",
            "Epoch 267/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4995 - accuracy: 0.8343 - val_loss: 220.0302 - val_accuracy: 0.1109\n",
            "Epoch 268/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4945 - accuracy: 0.8385 - val_loss: 236.3312 - val_accuracy: 0.1005\n",
            "Epoch 269/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4996 - accuracy: 0.8355 - val_loss: 187.7768 - val_accuracy: 0.1179\n",
            "Epoch 270/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4957 - accuracy: 0.8359 - val_loss: 227.4754 - val_accuracy: 0.1040\n",
            "Epoch 271/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4948 - accuracy: 0.8371 - val_loss: 202.3203 - val_accuracy: 0.1405\n",
            "Epoch 272/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4977 - accuracy: 0.8362 - val_loss: 205.8528 - val_accuracy: 0.1112\n",
            "Epoch 273/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4937 - accuracy: 0.8373 - val_loss: 210.3821 - val_accuracy: 0.1164\n",
            "Epoch 274/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4866 - accuracy: 0.8405 - val_loss: 205.2801 - val_accuracy: 0.1332\n",
            "Epoch 275/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4949 - accuracy: 0.8375 - val_loss: 199.5543 - val_accuracy: 0.1143\n",
            "Epoch 276/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4963 - accuracy: 0.8379 - val_loss: 202.4925 - val_accuracy: 0.1207\n",
            "Epoch 277/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4863 - accuracy: 0.8385 - val_loss: 184.2278 - val_accuracy: 0.1493\n",
            "Epoch 278/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4905 - accuracy: 0.8380 - val_loss: 183.8402 - val_accuracy: 0.1544\n",
            "Epoch 279/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4855 - accuracy: 0.8411 - val_loss: 192.5769 - val_accuracy: 0.1217\n",
            "Epoch 280/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4885 - accuracy: 0.8363 - val_loss: 158.3324 - val_accuracy: 0.1420\n",
            "Epoch 281/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4872 - accuracy: 0.8395 - val_loss: 188.9870 - val_accuracy: 0.1372\n",
            "Epoch 282/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4858 - accuracy: 0.8398 - val_loss: 207.6929 - val_accuracy: 0.1221\n",
            "Epoch 283/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4891 - accuracy: 0.8373 - val_loss: 186.6177 - val_accuracy: 0.1303\n",
            "Epoch 284/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4944 - accuracy: 0.8371 - val_loss: 189.6126 - val_accuracy: 0.1243\n",
            "Epoch 285/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4823 - accuracy: 0.8405 - val_loss: 209.5656 - val_accuracy: 0.1235\n",
            "Epoch 286/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4853 - accuracy: 0.8418 - val_loss: 218.0693 - val_accuracy: 0.1177\n",
            "Epoch 287/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4873 - accuracy: 0.8409 - val_loss: 203.6946 - val_accuracy: 0.1228\n",
            "Epoch 288/400\n",
            "703/703 [==============================] - 26s 38ms/step - loss: 0.4835 - accuracy: 0.8406 - val_loss: 233.1423 - val_accuracy: 0.1088\n",
            "Epoch 289/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4795 - accuracy: 0.8433 - val_loss: 223.1176 - val_accuracy: 0.1112\n",
            "Epoch 290/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4845 - accuracy: 0.8408 - val_loss: 228.2868 - val_accuracy: 0.1117\n",
            "Epoch 291/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4859 - accuracy: 0.8397 - val_loss: 235.1360 - val_accuracy: 0.1047\n",
            "Epoch 292/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4823 - accuracy: 0.8394 - val_loss: 215.1094 - val_accuracy: 0.1133\n",
            "Epoch 293/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4837 - accuracy: 0.8402 - val_loss: 233.9404 - val_accuracy: 0.1161\n",
            "Epoch 294/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4776 - accuracy: 0.8431 - val_loss: 210.0227 - val_accuracy: 0.1056\n",
            "Epoch 295/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4784 - accuracy: 0.8422 - val_loss: 226.6383 - val_accuracy: 0.1055\n",
            "Epoch 296/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4700 - accuracy: 0.8441 - val_loss: 269.0951 - val_accuracy: 0.1055\n",
            "Epoch 297/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4782 - accuracy: 0.8421 - val_loss: 248.7817 - val_accuracy: 0.1064\n",
            "Epoch 298/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4754 - accuracy: 0.8425 - val_loss: 212.3372 - val_accuracy: 0.1175\n",
            "Epoch 299/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4765 - accuracy: 0.8422 - val_loss: 218.8879 - val_accuracy: 0.1305\n",
            "Epoch 300/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4715 - accuracy: 0.8439 - val_loss: 213.7845 - val_accuracy: 0.1321\n",
            "Epoch 301/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4739 - accuracy: 0.8436 - val_loss: 207.6407 - val_accuracy: 0.1317\n",
            "Epoch 302/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4726 - accuracy: 0.8446 - val_loss: 235.0392 - val_accuracy: 0.1187\n",
            "Epoch 303/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4725 - accuracy: 0.8431 - val_loss: 226.7480 - val_accuracy: 0.1185\n",
            "Epoch 304/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4776 - accuracy: 0.8417 - val_loss: 205.2949 - val_accuracy: 0.1228\n",
            "Epoch 305/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4701 - accuracy: 0.8439 - val_loss: 230.7003 - val_accuracy: 0.1175\n",
            "Epoch 306/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4696 - accuracy: 0.8444 - val_loss: 214.6145 - val_accuracy: 0.1184\n",
            "Epoch 307/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4686 - accuracy: 0.8448 - val_loss: 197.0945 - val_accuracy: 0.1359\n",
            "Epoch 308/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4673 - accuracy: 0.8449 - val_loss: 238.4597 - val_accuracy: 0.1247\n",
            "Epoch 309/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4731 - accuracy: 0.8416 - val_loss: 205.0169 - val_accuracy: 0.1331\n",
            "Epoch 310/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4688 - accuracy: 0.8455 - val_loss: 188.4876 - val_accuracy: 0.1359\n",
            "Epoch 311/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4721 - accuracy: 0.8438 - val_loss: 204.8814 - val_accuracy: 0.1217\n",
            "Epoch 312/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4682 - accuracy: 0.8456 - val_loss: 217.6067 - val_accuracy: 0.1241\n",
            "Epoch 313/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4680 - accuracy: 0.8445 - val_loss: 241.2181 - val_accuracy: 0.1128\n",
            "Epoch 314/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4682 - accuracy: 0.8439 - val_loss: 213.1050 - val_accuracy: 0.1308\n",
            "Epoch 315/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4615 - accuracy: 0.8471 - val_loss: 189.0084 - val_accuracy: 0.1284\n",
            "Epoch 316/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4588 - accuracy: 0.8482 - val_loss: 238.8907 - val_accuracy: 0.1221\n",
            "Epoch 317/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4666 - accuracy: 0.8433 - val_loss: 214.7444 - val_accuracy: 0.1276\n",
            "Epoch 318/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4671 - accuracy: 0.8455 - val_loss: 196.8867 - val_accuracy: 0.1348\n",
            "Epoch 319/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4572 - accuracy: 0.8510 - val_loss: 211.4124 - val_accuracy: 0.1263\n",
            "Epoch 320/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4614 - accuracy: 0.8464 - val_loss: 228.9816 - val_accuracy: 0.1236\n",
            "Epoch 321/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4655 - accuracy: 0.8462 - val_loss: 256.5800 - val_accuracy: 0.1141\n",
            "Epoch 322/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4602 - accuracy: 0.8472 - val_loss: 246.9170 - val_accuracy: 0.1103\n",
            "Epoch 323/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4590 - accuracy: 0.8478 - val_loss: 242.8340 - val_accuracy: 0.1243\n",
            "Epoch 324/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4592 - accuracy: 0.8493 - val_loss: 204.2156 - val_accuracy: 0.1384\n",
            "Epoch 325/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4598 - accuracy: 0.8473 - val_loss: 209.7090 - val_accuracy: 0.1347\n",
            "Epoch 326/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4612 - accuracy: 0.8453 - val_loss: 227.7130 - val_accuracy: 0.1211\n",
            "Epoch 327/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4616 - accuracy: 0.8471 - val_loss: 226.7716 - val_accuracy: 0.1124\n",
            "Epoch 328/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4603 - accuracy: 0.8486 - val_loss: 205.7991 - val_accuracy: 0.1280\n",
            "Epoch 329/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4635 - accuracy: 0.8480 - val_loss: 220.8672 - val_accuracy: 0.1233\n",
            "Epoch 330/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4578 - accuracy: 0.8487 - val_loss: 186.7447 - val_accuracy: 0.1373\n",
            "Epoch 331/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4616 - accuracy: 0.8468 - val_loss: 242.8602 - val_accuracy: 0.1163\n",
            "Epoch 332/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4594 - accuracy: 0.8489 - val_loss: 233.4437 - val_accuracy: 0.1160\n",
            "Epoch 333/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4517 - accuracy: 0.8521 - val_loss: 217.1350 - val_accuracy: 0.1135\n",
            "Epoch 334/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4604 - accuracy: 0.8492 - val_loss: 256.1458 - val_accuracy: 0.1179\n",
            "Epoch 335/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4587 - accuracy: 0.8474 - val_loss: 254.0548 - val_accuracy: 0.1265\n",
            "Epoch 336/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4521 - accuracy: 0.8507 - val_loss: 248.5971 - val_accuracy: 0.1021\n",
            "Epoch 337/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4511 - accuracy: 0.8511 - val_loss: 227.7283 - val_accuracy: 0.1068\n",
            "Epoch 338/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4555 - accuracy: 0.8474 - val_loss: 232.6301 - val_accuracy: 0.0995\n",
            "Epoch 339/400\n",
            "703/703 [==============================] - 28s 40ms/step - loss: 0.4444 - accuracy: 0.8540 - val_loss: 218.8838 - val_accuracy: 0.1208\n",
            "Epoch 340/400\n",
            "703/703 [==============================] - 28s 39ms/step - loss: 0.4545 - accuracy: 0.8494 - val_loss: 229.2332 - val_accuracy: 0.0944\n",
            "Epoch 341/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4469 - accuracy: 0.8525 - val_loss: 274.5569 - val_accuracy: 0.0964\n",
            "Epoch 342/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4500 - accuracy: 0.8512 - val_loss: 271.2735 - val_accuracy: 0.1075\n",
            "Epoch 343/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4485 - accuracy: 0.8501 - val_loss: 226.0682 - val_accuracy: 0.1000\n",
            "Epoch 344/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4490 - accuracy: 0.8503 - val_loss: 195.3983 - val_accuracy: 0.1215\n",
            "Epoch 345/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4491 - accuracy: 0.8508 - val_loss: 225.7041 - val_accuracy: 0.1145\n",
            "Epoch 346/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4466 - accuracy: 0.8533 - val_loss: 232.4846 - val_accuracy: 0.1145\n",
            "Epoch 347/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4427 - accuracy: 0.8538 - val_loss: 206.5468 - val_accuracy: 0.1236\n",
            "Epoch 348/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4469 - accuracy: 0.8520 - val_loss: 182.4161 - val_accuracy: 0.1372\n",
            "Epoch 349/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4404 - accuracy: 0.8544 - val_loss: 207.3354 - val_accuracy: 0.1100\n",
            "Epoch 350/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4470 - accuracy: 0.8514 - val_loss: 170.6259 - val_accuracy: 0.1331\n",
            "Epoch 351/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4437 - accuracy: 0.8526 - val_loss: 157.5744 - val_accuracy: 0.1515\n",
            "Epoch 352/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4468 - accuracy: 0.8516 - val_loss: 218.6644 - val_accuracy: 0.1165\n",
            "Epoch 353/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4484 - accuracy: 0.8517 - val_loss: 204.8212 - val_accuracy: 0.1217\n",
            "Epoch 354/400\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4447 - accuracy: 0.8537 - val_loss: 226.3477 - val_accuracy: 0.1253\n",
            "Epoch 355/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4449 - accuracy: 0.8543 - val_loss: 269.9465 - val_accuracy: 0.1132\n",
            "Epoch 356/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4456 - accuracy: 0.8516 - val_loss: 236.2221 - val_accuracy: 0.1192\n",
            "Epoch 357/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4462 - accuracy: 0.8530 - val_loss: 253.4114 - val_accuracy: 0.1201\n",
            "Epoch 358/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4446 - accuracy: 0.8519 - val_loss: 229.6408 - val_accuracy: 0.1175\n",
            "Epoch 359/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4418 - accuracy: 0.8544 - val_loss: 219.6728 - val_accuracy: 0.1156\n",
            "Epoch 360/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4439 - accuracy: 0.8536 - val_loss: 242.2851 - val_accuracy: 0.1073\n",
            "Epoch 361/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4326 - accuracy: 0.8560 - val_loss: 210.6931 - val_accuracy: 0.1087\n",
            "Epoch 362/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4416 - accuracy: 0.8545 - val_loss: 221.4818 - val_accuracy: 0.1243\n",
            "Epoch 363/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4439 - accuracy: 0.8531 - val_loss: 171.3561 - val_accuracy: 0.1465\n",
            "Epoch 364/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4354 - accuracy: 0.8545 - val_loss: 196.9530 - val_accuracy: 0.1339\n",
            "Epoch 365/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4430 - accuracy: 0.8543 - val_loss: 237.5649 - val_accuracy: 0.1155\n",
            "Epoch 366/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4367 - accuracy: 0.8542 - val_loss: 216.1324 - val_accuracy: 0.1163\n",
            "Epoch 367/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4404 - accuracy: 0.8543 - val_loss: 232.4392 - val_accuracy: 0.1196\n",
            "Epoch 368/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4368 - accuracy: 0.8540 - val_loss: 241.5257 - val_accuracy: 0.1083\n",
            "Epoch 369/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4356 - accuracy: 0.8550 - val_loss: 214.6351 - val_accuracy: 0.1111\n",
            "Epoch 370/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4333 - accuracy: 0.8583 - val_loss: 224.7140 - val_accuracy: 0.1199\n",
            "Epoch 371/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4343 - accuracy: 0.8568 - val_loss: 218.6558 - val_accuracy: 0.1244\n",
            "Epoch 372/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4418 - accuracy: 0.8528 - val_loss: 219.7984 - val_accuracy: 0.1176\n",
            "Epoch 373/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4310 - accuracy: 0.8563 - val_loss: 197.5622 - val_accuracy: 0.1305\n",
            "Epoch 374/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4345 - accuracy: 0.8548 - val_loss: 221.7427 - val_accuracy: 0.1209\n",
            "Epoch 375/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4304 - accuracy: 0.8575 - val_loss: 201.9527 - val_accuracy: 0.1092\n",
            "Epoch 376/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4319 - accuracy: 0.8562 - val_loss: 227.8298 - val_accuracy: 0.1049\n",
            "Epoch 377/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4302 - accuracy: 0.8558 - val_loss: 203.0146 - val_accuracy: 0.1203\n",
            "Epoch 378/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4371 - accuracy: 0.8556 - val_loss: 202.6255 - val_accuracy: 0.1125\n",
            "Epoch 379/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4290 - accuracy: 0.8585 - val_loss: 242.4131 - val_accuracy: 0.1225\n",
            "Epoch 380/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4303 - accuracy: 0.8590 - val_loss: 238.5562 - val_accuracy: 0.1028\n",
            "Epoch 381/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4367 - accuracy: 0.8560 - val_loss: 217.8495 - val_accuracy: 0.1079\n",
            "Epoch 382/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4263 - accuracy: 0.8586 - val_loss: 202.5253 - val_accuracy: 0.1377\n",
            "Epoch 383/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4255 - accuracy: 0.8590 - val_loss: 202.2164 - val_accuracy: 0.1327\n",
            "Epoch 384/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4277 - accuracy: 0.8585 - val_loss: 226.4001 - val_accuracy: 0.1116\n",
            "Epoch 385/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4259 - accuracy: 0.8580 - val_loss: 217.9515 - val_accuracy: 0.1305\n",
            "Epoch 386/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4271 - accuracy: 0.8572 - val_loss: 235.5094 - val_accuracy: 0.1243\n",
            "Epoch 387/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4273 - accuracy: 0.8582 - val_loss: 264.8459 - val_accuracy: 0.1068\n",
            "Epoch 388/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4292 - accuracy: 0.8586 - val_loss: 196.9375 - val_accuracy: 0.1233\n",
            "Epoch 389/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4248 - accuracy: 0.8600 - val_loss: 218.3012 - val_accuracy: 0.1148\n",
            "Epoch 390/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4275 - accuracy: 0.8602 - val_loss: 230.8767 - val_accuracy: 0.1177\n",
            "Epoch 391/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4271 - accuracy: 0.8583 - val_loss: 196.7101 - val_accuracy: 0.1191\n",
            "Epoch 392/400\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4282 - accuracy: 0.8592 - val_loss: 204.7354 - val_accuracy: 0.1128\n",
            "Epoch 393/400\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4249 - accuracy: 0.8586 - val_loss: 251.3656 - val_accuracy: 0.1080\n",
            "Epoch 394/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4276 - accuracy: 0.8571 - val_loss: 248.5485 - val_accuracy: 0.0952\n",
            "Epoch 395/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4237 - accuracy: 0.8593 - val_loss: 265.6397 - val_accuracy: 0.0991\n",
            "Epoch 396/400\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4208 - accuracy: 0.8603 - val_loss: 234.3511 - val_accuracy: 0.1171\n",
            "Epoch 397/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4276 - accuracy: 0.8574 - val_loss: 218.9412 - val_accuracy: 0.1249\n",
            "Epoch 398/400\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4212 - accuracy: 0.8606 - val_loss: 263.6512 - val_accuracy: 0.0961\n",
            "Epoch 399/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4205 - accuracy: 0.8594 - val_loss: 226.9089 - val_accuracy: 0.0996\n",
            "Epoch 400/400\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4219 - accuracy: 0.8580 - val_loss: 218.4820 - val_accuracy: 0.1085\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.4869 - accuracy: 0.8522\n",
            "> 85.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ImrogfmwhBVI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}